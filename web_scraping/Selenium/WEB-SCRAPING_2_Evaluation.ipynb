{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da1eb13c622284f",
   "metadata": {},
   "source": [
    "## Web scraping evaluation assignment 2 (Selenium)\n",
    "* ### Name: Rajib Dutta\n",
    "* ### Email: duttarajib78@gmail.com\n",
    "* ### Internship Batch: DS2402"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28296dc960cea76e",
   "metadata": {},
   "source": [
    "### Q1: In this question you have to scrape data using the filters available on the webpage You have to use the location and\n",
    "salary filter.\n",
    "You have to scrape data for ‚ÄúData Scientist‚Äù designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is ‚ÄúDelhi/NCR‚Äù. The salary filter to be used is ‚Äú3-6‚Äù lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the web page https://www.naukri.com/\n",
    "2. Enter ‚ÄúData Scientist‚Äù in ‚ÄúSkill, Designations, and Companies‚Äù field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb79d09833d0e97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:54:42.535715Z",
     "start_time": "2024-04-11T14:53:08.576715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Exerience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Kashsam Data Solutions</td>\n",
       "      <td>3 - 7 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Scienaptic Systems</td>\n",
       "      <td>2 - 7 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurugram, Bengaluru</td>\n",
       "      <td>Blackbuck</td>\n",
       "      <td>3 - 7 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Wizaltia Hr Solutions</td>\n",
       "      <td>2 - 7 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Kmart</td>\n",
       "      <td>1 - 2 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>KAS Services</td>\n",
       "      <td>1 - 2 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist/ Data Scientist</td>\n",
       "      <td>Mumbai, Pune, Chennai, Gurugram, Bengaluru</td>\n",
       "      <td>Neal Analytics</td>\n",
       "      <td>3 - 7 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Elitefit.ai</td>\n",
       "      <td>3 - 7 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Fort Technologies</td>\n",
       "      <td>1 - 3 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead Customer Success - Data Scientist</td>\n",
       "      <td>Pune, Gurugram</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>2 - 4 years</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Job_Title  \\\n",
       "0                          Data Scientist   \n",
       "1                          Data Scientist   \n",
       "2                          Data Scientist   \n",
       "3                   Python Data Scientist   \n",
       "4                Associate Data Scientist   \n",
       "5                Associate Data Scientist   \n",
       "6   Senior Data Scientist/ Data Scientist   \n",
       "7                     Lead Data Scientist   \n",
       "8                          Data Scientist   \n",
       "9  Lead Customer Success - Data Scientist   \n",
       "\n",
       "                                            Location                 Company  \\\n",
       "0  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...  Kashsam Data Solutions   \n",
       "1  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...      Scienaptic Systems   \n",
       "2                                Gurugram, Bengaluru               Blackbuck   \n",
       "3  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...   Wizaltia Hr Solutions   \n",
       "4  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...                   Kmart   \n",
       "5  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...            KAS Services   \n",
       "6         Mumbai, Pune, Chennai, Gurugram, Bengaluru          Neal Analytics   \n",
       "7  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...             Elitefit.ai   \n",
       "8  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...       Fort Technologies   \n",
       "9                                     Pune, Gurugram           ZS Associates   \n",
       "\n",
       "     Exerience  \n",
       "0  3 - 7 years  \n",
       "1  2 - 7 years  \n",
       "2  3 - 7 years  \n",
       "3  2 - 7 years  \n",
       "4  1 - 2 years  \n",
       "5  1 - 2 years  \n",
       "6  3 - 7 years  \n",
       "7  3 - 7 years  \n",
       "8  1 - 3 years  \n",
       "9  2 - 4 years  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium.webdriver import Keys, ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "actions = ActionChains(driver)\n",
    "\n",
    "skill_xpath='//div[@class=\"keywordSugg\"]/div/div/div/div[1]/div/input'\n",
    "search_button_xpath='//div[@class=\"qsbSubmit\"]'\n",
    "skill_text_box=WebDriverWait(driver,30).until(expected_conditions.presence_of_element_located((By.XPATH, skill_xpath)))\n",
    "search_button=WebDriverWait(driver,30).until(expected_conditions.element_to_be_clickable((By.XPATH, search_button_xpath)))\n",
    "actions.click(on_element=skill_text_box)\n",
    "actions.send_keys('Data Scientist')\n",
    "actions.click(on_element=search_button)\n",
    "actions.pause(5)\n",
    "actions.perform()\n",
    "actions.reset_actions()\n",
    "\n",
    "location_checkbox_xpath='//div[@class=\"styles_filter-wrapper-component__4OBpS\"]/div[5]/div[2]/div[2]/label/i'\n",
    "location_checkbox=WebDriverWait(driver,10).until(expected_conditions.presence_of_element_located((By.XPATH, location_checkbox_xpath)))\n",
    "actions.click(on_element=location_checkbox)\n",
    "actions.pause(5)\n",
    "actions.perform()\n",
    "actions.reset_actions()\n",
    "\n",
    "salary_checkbox_xpath='//div[@class=\"styles_filter-wrapper-component__4OBpS\"]/div[6]/div[2]/div[2]/label/i'\n",
    "salary_checkbox=WebDriverWait(driver,10).until(expected_conditions.presence_of_element_located((By.XPATH, salary_checkbox_xpath)))\n",
    "actions.click(on_element=salary_checkbox)\n",
    "actions.pause(5)\n",
    "actions.perform()\n",
    "actions.reset_actions()\n",
    "\n",
    "parent_page=driver.current_window_handle\n",
    "job_df=pd.DataFrame(columns=['Job_Title','Location','Company','Exerience'])\n",
    "counter=0\n",
    "i=0\n",
    "while True:\n",
    "    i+=1\n",
    "    if counter==10:\n",
    "        break\n",
    "    job_link_xpath=f'//div[@class=\"styles_jlc__main__VdwtF\"]/div[{i}]/div/div[1]/a'\n",
    "    try:\n",
    "        job_link=WebDriverWait(driver,10).until(expected_conditions.element_to_be_clickable((By.XPATH, job_link_xpath)))\n",
    "    except:\n",
    "        continue\n",
    "    driver.execute_script(\"arguments[0].click();\", job_link)\n",
    "    actions.pause(5).perform()\n",
    "    actions.reset_actions()\n",
    "    \n",
    "    child_page=driver.window_handles[-1]\n",
    "    driver.switch_to.window(child_page)\n",
    "    title=WebDriverWait(driver,10).until(expected_conditions.presence_of_element_located((By.XPATH, '//h1[@class=\"styles_jd-header-title__rZwM1\"]'))).text\n",
    "    location=WebDriverWait(driver,10).until(expected_conditions.presence_of_element_located((By.XPATH, '//span[@class=\"styles_jhc__location__W_pVs\"]'))).text\n",
    "    company=WebDriverWait(driver,10).until(expected_conditions.presence_of_element_located((By.XPATH, '//div[@class=\"styles_jd-header-comp-name__MvqAI\"]/a'))).text\n",
    "    experience=WebDriverWait(driver,10).until(expected_conditions.presence_of_element_located((By.XPATH, '//div[@class=\"styles_jhc__exp__k_giM\"]/span'))).text\n",
    "    driver.close()\n",
    "    driver.switch_to.window(parent_page)\n",
    "    job_df.loc[counter]=(title, location, company, experience)\n",
    "    counter+=1\n",
    "driver.quit()\n",
    "job_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c12cac6ee8afa",
   "metadata": {},
   "source": [
    "### Q2: Write a python program to scrape data for ‚ÄúData Scientist‚Äù Job position in ‚ÄúBangalore‚Äù location. You have to scrape the\n",
    "job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter ‚ÄúData Analyst‚Äù in ‚ÄúJob title, Skills‚Äù field and enter ‚ÄúBangalore‚Äù in ‚Äúenter the location‚Äù field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b49f58415536c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:55:28.523963Z",
     "start_time": "2024-04-11T14:54:42.537626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist Opening</td>\n",
       "      <td>Oman</td>\n",
       "      <td>RADHIKA ENTERPRISES</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>ALIKE THOUGHTS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>5 to 10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist Urgent Recruitment</td>\n",
       "      <td>Oman</td>\n",
       "      <td>Divya Staffing Solution</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Opening</td>\n",
       "      <td>Oman</td>\n",
       "      <td>Divya Staffing Solution</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist Recruitment</td>\n",
       "      <td>Oman</td>\n",
       "      <td>RADHIKA ENTERPRISES</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist Vacancy</td>\n",
       "      <td>Oman</td>\n",
       "      <td>Divya Staffing Solution</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Oman</td>\n",
       "      <td>Divya Staffing Solution</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist Opening</td>\n",
       "      <td>Canada</td>\n",
       "      <td>RENUKA INTERPRISES</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist Opening</td>\n",
       "      <td>Canada</td>\n",
       "      <td>RENUKA INTERPRISES</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist Recruitment</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>RADHIKA ENTERPRISES</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title   Location  \\\n",
       "0             Data Scientist Opening       Oman   \n",
       "1                     Data Scientist  Bangalore   \n",
       "2  Data Scientist Urgent Recruitment       Oman   \n",
       "3             Data Scientist Opening       Oman   \n",
       "4         Data Scientist Recruitment       Oman   \n",
       "5             Data Scientist Vacancy       Oman   \n",
       "6          Hiring For Data Scientist       Oman   \n",
       "7             Data Scientist Opening     Canada   \n",
       "8             Data Scientist Opening     Canada   \n",
       "9         Data Scientist Recruitment  Bangalore   \n",
       "\n",
       "                                    Company   Experience  \n",
       "0                       RADHIKA ENTERPRISES   0 to 4 Yrs  \n",
       "1  ALIKE THOUGHTS SOLUTIONS PRIVATE LIMITED  5 to 10 Yrs  \n",
       "2                   Divya Staffing Solution   0 to 4 Yrs  \n",
       "3                   Divya Staffing Solution   0 to 4 Yrs  \n",
       "4                       RADHIKA ENTERPRISES   0 to 4 Yrs  \n",
       "5                   Divya Staffing Solution   0 to 4 Yrs  \n",
       "6                   Divya Staffing Solution   0 to 4 Yrs  \n",
       "7                        RENUKA INTERPRISES   0 to 4 Yrs  \n",
       "8                        RENUKA INTERPRISES   0 to 4 Yrs  \n",
       "9                       RADHIKA ENTERPRISES   0 to 4 Yrs  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get('https://www.shine.com/')\n",
    "\n",
    "action = ActionChains(driver)\n",
    "\n",
    "jobs_menue=WebDriverWait(driver,10).until(expected_conditions.presence_of_element_located((By.XPATH, '//input[@class=\"input\"]')))\n",
    "action.click(on_element=jobs_menue).perform()\n",
    "action.reset_actions()\n",
    "\n",
    "skill_text_box=WebDriverWait(driver,10).until(expected_conditions.presence_of_element_located((By.XPATH, '//input[@id=\"id_q\"]')))\n",
    "location_text_box=WebDriverWait(driver,10).until(expected_conditions.presence_of_element_located((By.XPATH, '//input[@id=\"id_loc\"]')))\n",
    "search_button=WebDriverWait(driver,10).until(expected_conditions.element_to_be_clickable((By.XPATH, '//button[@class=\" btn btn-secondary undefined\"]')))\n",
    "action.click(on_element=skill_text_box)\n",
    "action.send_keys('Data Scientist')\n",
    "action.click(on_element=location_text_box)\n",
    "action.send_keys('Bangalore')\n",
    "action.click(on_element=search_button)\n",
    "action.pause(5)\n",
    "action.perform()\n",
    "action.reset_actions()\n",
    "\n",
    "job_df=pd.DataFrame(columns=['Title', 'Location', 'Company', 'Experience'])\n",
    "for i in range(10):\n",
    "    job_link_xpath=f'//div[@class=\"parentClass position-relative\"]/div[{i+1}]/div/div/strong/a'\n",
    "    job_link=WebDriverWait(driver,10).until(expected_conditions.element_to_be_clickable((By.XPATH, job_link_xpath)))\n",
    "    driver.execute_script(\"arguments[0].click();\", job_link)\n",
    "    action.pause(3).perform()\n",
    "    action.reset_actions()\n",
    "    \n",
    "    title_xpath='//h2[@class=\"font-size-24\"]'\n",
    "    title=WebDriverWait(driver,10).until(expected_conditions.visibility_of_element_located((By.XPATH, title_xpath))).text.strip()\n",
    "    location_xpath='//div[@class=\" JobDetailWidget_jobCard_lists_item__w6Yow JobDetailWidget_locationIcon__u85a7\"]/a'\n",
    "    location=WebDriverWait(driver,10).until(expected_conditions.visibility_of_element_located((By.XPATH, location_xpath))).text.strip()\n",
    "    company_xpath='//div[@class=\"JobDetailWidget_jobCard_cName__qvsdW\"]/span'\n",
    "    company=WebDriverWait(driver,10).until(expected_conditions.visibility_of_element_located((By.XPATH, company_xpath))).text.strip()\n",
    "    experience_xpath='//div[@class=\"JobDetailWidget_jobCard_lists_item__w6Yow JobDetailWidget_jobIcon__mjaNB undefined\"]'\n",
    "    experience=WebDriverWait(driver,10).until(expected_conditions.visibility_of_element_located((By.XPATH, experience_xpath))).text.strip()\n",
    "    job_df.loc[i]=(title, location, company, experience)\n",
    "driver.quit()\n",
    "job_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb724d62ee76e2f",
   "metadata": {},
   "source": [
    "### Q3: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "\n",
    "You have to scrape this data for first 100reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eb1396db64128af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T14:56:31.691554Z",
     "start_time": "2024-04-11T14:55:28.525326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Photos super</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Feeling awesome after getting the delivery of ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Good Camera</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at all</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Value for money üòç</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Quality camera</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Classy product</td>\n",
       "      <td>Outstanding performance this phone</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Good</td>\n",
       "      <td>only the name worth it with d price.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>A perfect phone and a good battery super camer...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Best phone</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Review_summary                                        Full_review  \\\n",
       "0      Perfect product!                                       Photos super   \n",
       "1     Worth every penny  Feeling awesome after getting the delivery of ...   \n",
       "2   Best in the market!                                        Good Camera   \n",
       "3             Wonderful                             This is amazing at all   \n",
       "4     Terrific purchase                                  Value for money üòç   \n",
       "..                  ...                                                ...   \n",
       "95            Wonderful                                     Quality camera   \n",
       "96       Classy product                 Outstanding performance this phone   \n",
       "97                 Good               only the name worth it with d price.   \n",
       "98            Excellent  A perfect phone and a good battery super camer...   \n",
       "99            Brilliant                                         Best phone   \n",
       "\n",
       "   Rating  \n",
       "0       5  \n",
       "1       5  \n",
       "2       5  \n",
       "3       5  \n",
       "4       5  \n",
       "..    ...  \n",
       "95      5  \n",
       "96      5  \n",
       "97      3  \n",
       "98      5  \n",
       "99      5  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "browser=webdriver.Chrome()\n",
    "browser.maximize_window()\n",
    "browser.get('https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART')\n",
    "review_section_xpath='//div[@class=\"col _2wzgFH K0kLPL\"]'\n",
    "\n",
    "review_df=pd.DataFrame(columns=['Review_summary', 'Full_review', 'Rating'])\n",
    "page_counter=1\n",
    "ratings=[]\n",
    "summaries=[]\n",
    "reviews=[]\n",
    "while True:\n",
    "    if len(reviews)==100:\n",
    "        break\n",
    "        \n",
    "    rating_elements=WebDriverWait(browser,10).until(expected_conditions.presence_of_all_elements_located((By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')))\n",
    "    summary_elements=WebDriverWait(browser,10).until(expected_conditions.presence_of_all_elements_located((By.XPATH, '//p[@class=\"_2-N8zT\"]')))\n",
    "    review_elements=WebDriverWait(browser,10).until(expected_conditions.presence_of_all_elements_located((By.XPATH, '//div[@class=\"t-ZTKy\"]/div/div')))\n",
    "    \n",
    "    for rating in rating_elements:\n",
    "        ratings.append(rating.text.strip())\n",
    "        \n",
    "    for summary in summary_elements:\n",
    "        summaries.append(summary.text.strip())\n",
    "        \n",
    "    for review in review_elements:\n",
    "        reviews.append(review.text.strip())\n",
    "        \n",
    "    next_button_xpath='//a[@class=\"_1LKTO3\"]'\n",
    "    if page_counter>1:\n",
    "        next_button_xpath='//a[@class=\"_1LKTO3\"][2]'\n",
    "        \n",
    "    next_button=WebDriverWait(browser,10).until(expected_conditions.element_to_be_clickable((By.XPATH, next_button_xpath)))\n",
    "    browser.execute_script(\"arguments[0].click();\", next_button)\n",
    "    actions=ActionChains(browser)\n",
    "    actions.pause(5).perform()\n",
    "    actions.reset_actions()\n",
    "    page_counter+=1\n",
    "    \n",
    "browser.quit()\n",
    "review_df.Review_summary=summaries\n",
    "review_df.Full_review=reviews\n",
    "review_df.Rating=ratings\n",
    "review_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c31d336d9ae9a8",
   "metadata": {},
   "source": [
    "### Q4: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for ‚Äúsneakers‚Äù in the search\n",
    "field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82148cb83507e535",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:05:33.974120Z",
     "start_time": "2024-04-11T14:56:31.693840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Trending Stylish Casual Outdoor Shoes Sneakers...</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>2 Combo Sneaker Shoes Sneakers For Men  (Grey,...</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Trending Stylish Casual Outdoor Shoes Sneakers...</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Sneakers For Women  (White)</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Colour Blocked Shoes For Boys ...</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Pacer Fire Sneakers For Men  (Green)</td>\n",
       "      <td>1,889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>SUPERSTAR Sneakers For Men  (White)</td>\n",
       "      <td>1,216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>LACOSTE</td>\n",
       "      <td>Sneakers For Women  (White)</td>\n",
       "      <td>10,569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Casual Sneaker Shoes For Men | Comfortable, Br...</td>\n",
       "      <td>1,119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Xtoon</td>\n",
       "      <td>Lightweight,Comfort,Summer,Trendy,Walking,Outd...</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Brand                                        Description  \\\n",
       "0                URBANBOX  Trending Stylish Casual Outdoor Shoes Sneakers...   \n",
       "1                  BRUTON  2 Combo Sneaker Shoes Sneakers For Men  (Grey,...   \n",
       "2                URBANBOX  Trending Stylish Casual Outdoor Shoes Sneakers...   \n",
       "3               Deals4you                        Sneakers For Women  (White)   \n",
       "4            Robbie jones  Casual Sneakers Colour Blocked Shoes For Boys ...   \n",
       "..                    ...                                                ...   \n",
       "95                   PUMA               Pacer Fire Sneakers For Men  (Green)   \n",
       "96  HRX by Hrithik Roshan                SUPERSTAR Sneakers For Men  (White)   \n",
       "97                LACOSTE                        Sneakers For Women  (White)   \n",
       "98               RED TAPE  Casual Sneaker Shoes For Men | Comfortable, Br...   \n",
       "99                  Xtoon  Lightweight,Comfort,Summer,Trendy,Walking,Outd...   \n",
       "\n",
       "     Price  \n",
       "0      299  \n",
       "1      499  \n",
       "2      299  \n",
       "3      379  \n",
       "4      449  \n",
       "..     ...  \n",
       "95   1,889  \n",
       "96   1,216  \n",
       "97  10,569  \n",
       "98   1,119  \n",
       "99     498  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "browser=webdriver.Chrome()\n",
    "browser.maximize_window()\n",
    "browser.get('https://www.flipkart.com/')\n",
    "\n",
    "search_box_xpath='//input[@class=\"Pke_EE\"]'\n",
    "search_button_xpath='//button[@class=\"_2iLD__\"]'\n",
    "search_box=WebDriverWait(browser,10).until(expected_conditions.presence_of_element_located((By.XPATH, search_box_xpath)))\n",
    "search_button=WebDriverWait(browser,10).until(expected_conditions.element_to_be_clickable((By.XPATH, search_button_xpath)))\n",
    "\n",
    "actions=ActionChains(browser)\n",
    "actions.click(on_element=search_box)\n",
    "actions.send_keys('sneakers')\n",
    "actions.click(on_element=search_button)\n",
    "actions.pause(5)\n",
    "actions.perform()\n",
    "actions.reset_actions()\n",
    "\n",
    "products_df=pd.DataFrame(columns=['Brand', 'Description', 'Price'])\n",
    "counter=0\n",
    "page_counter=1\n",
    "brands=[]\n",
    "descriptions=[]\n",
    "prices=[]\n",
    "while True:        \n",
    "    product_link_xpath='//a[@class=\"_2UzuFa\"]'\n",
    "    product_links=WebDriverWait(browser,10).until(expected_conditions.presence_of_all_elements_located((By.XPATH, product_link_xpath)))\n",
    "    parent_window=browser.current_window_handle\n",
    "    \n",
    "    for product_link in product_links:\n",
    "        if counter==100:\n",
    "            break\n",
    "            \n",
    "        browser.execute_script(\"arguments[0].click();\", product_link)\n",
    "        actions.pause(5).perform()\n",
    "        actions.reset_actions()\n",
    "        detail_child_window=browser.window_handles[-1]\n",
    "        browser.switch_to.window(detail_child_window)\n",
    "        try:\n",
    "            brand=WebDriverWait(browser,10).until(expected_conditions.presence_of_element_located((By.XPATH, '//h1[@class=\"yhB1nd\"]/span[1]'))).text.strip()\n",
    "            description=WebDriverWait(browser,10).until(expected_conditions.presence_of_element_located((By.XPATH, '//span[@class=\"B_NuCI\"]'))).text.strip()\n",
    "            price=WebDriverWait(browser,10).until(expected_conditions.presence_of_element_located((By.XPATH, '//div[@class=\"_30jeq3 _16Jk6d\"]'))).text.replace('‚Çπ','').strip()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            browser.close()\n",
    "            browser.switch_to.window(parent_window)\n",
    "            continue\n",
    "        \n",
    "        brands.append(brand)\n",
    "        descriptions.append(description)\n",
    "        prices.append(price)\n",
    "        counter+=1\n",
    "        \n",
    "        browser.close()\n",
    "        browser.switch_to.window(parent_window)\n",
    "    \n",
    "    if page_counter>1:\n",
    "        next_button_xpath='//a[@class=\"_1LKTO3\"][2]'\n",
    "    else:\n",
    "        next_button_xpath='//a[@class=\"_1LKTO3\"]'\n",
    "        \n",
    "    if counter==100:\n",
    "        break\n",
    "        \n",
    "    next_button=WebDriverWait(browser,10).until(expected_conditions.element_to_be_clickable((By.XPATH, next_button_xpath)))\n",
    "    browser.execute_script(\"arguments[0].click();\", next_button)\n",
    "    actions.pause(5).perform()\n",
    "    actions.reset_actions()\n",
    "    page_counter+=1\n",
    "\n",
    "browser.quit()\n",
    "products_df.Brand=brands\n",
    "products_df.Description=descriptions\n",
    "products_df.Price=prices\n",
    "products_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29292aa7e37114d4",
   "metadata": {},
   "source": [
    "### Q5: Go to webpage https://www.amazon.in/ Enter ‚ÄúLaptop‚Äù in the search field and then click the search icon. Then set CPU\n",
    "Type filter to ‚ÄúIntel Core i7‚Äù as shown in the below image.\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61ce6bd40e279278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:06:51.143351Z",
     "start_time": "2024-04-11T15:05:33.975321Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49,650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSI Modern 15, Intel 13th Gen. i7-1355U, 40CM ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>67,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Core i7 12th Gen 1...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>62,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP OMEN Gaming Laptop, Intel Core i7-14700HX (...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1,38,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 12th Gen Core i7 15....</td>\n",
       "      <td>3.0</td>\n",
       "      <td>59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion X360 11th Gen Intel Core i7 14\" (3...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>67,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>76,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dell G15 5530 Gaming Laptop, Intel i7-13650HX/...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>99,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Rating     Price\n",
       "0  MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...    4.0    49,650\n",
       "1  MSI Modern 15, Intel 13th Gen. i7-1355U, 40CM ...    4.0    65,990\n",
       "2  ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...    4.4    67,990\n",
       "3  Lenovo IdeaPad Slim 3 Intel Core i7 12th Gen 1...    4.1    62,490\n",
       "4  HP OMEN Gaming Laptop, Intel Core i7-14700HX (...    4.3  1,38,990\n",
       "5  Lenovo ThinkBook 15 Intel 12th Gen Core i7 15....    3.0    59,990\n",
       "6  ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...    3.9    59,990\n",
       "7  HP Pavilion X360 11th Gen Intel Core i7 14\" (3...    3.8    67,990\n",
       "8  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...    4.2    76,990\n",
       "9  Dell G15 5530 Gaming Laptop, Intel i7-13650HX/...    4.1    99,990"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "browser=webdriver.Chrome()\n",
    "browser.maximize_window()\n",
    "browser.get('https://www.amazon.in/')\n",
    "\n",
    "search_box_xpath='//input[@id=\"twotabsearchtextbox\"]'\n",
    "search_button_xpath='//input[@id=\"nav-search-submit-button\"]'\n",
    "cpu_type_filter_checkbox_xpath=\"//span[@class='a-size-base a-color-base'][normalize-space()='Intel Core i7']\"\n",
    "laptop_link_xpath='//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"]/a'\n",
    "title_xpath='//h1[@id=\"title\"]/span'\n",
    "rating_xpath=\"//div[@id='averageCustomerReviews_feature_div']//span[@class='a-size-base a-color-base']\"\n",
    "price_xpath='//div[@class=\"a-section a-spacing-none aok-align-center aok-relative\"]/span[3]/span[2]/span[2]'\n",
    "\n",
    "search_box=WebDriverWait(browser,10).until(expected_conditions.element_to_be_clickable((By.XPATH, search_box_xpath)))\n",
    "search_button=WebDriverWait(browser,10).until(expected_conditions.element_to_be_clickable((By.XPATH, search_button_xpath)))\n",
    "\n",
    "actions=ActionChains(browser)\n",
    "actions.click(on_element=search_box)\n",
    "actions.send_keys('Laptop')\n",
    "actions.click(on_element=search_button)\n",
    "actions.pause(5)\n",
    "actions.perform()\n",
    "actions.reset_actions()\n",
    "\n",
    "cpu_type_filter_checkbox=WebDriverWait(browser,10).until(expected_conditions.visibility_of_element_located((By.XPATH, cpu_type_filter_checkbox_xpath)))\n",
    "browser.execute_script(\"arguments[0].click();\", cpu_type_filter_checkbox)\n",
    "actions.pause(5).perform()\n",
    "actions.reset_actions()\n",
    "\n",
    "parent_window=browser.current_window_handle\n",
    "laptop_details_links=WebDriverWait(browser,10).until(expected_conditions.presence_of_all_elements_located((By.XPATH, laptop_link_xpath)))\n",
    "\n",
    "titles=[]\n",
    "ratings=[]\n",
    "prices=[]\n",
    "laptop_df=pd.DataFrame(columns=['Title', 'Rating', 'Price'])\n",
    "for i, laptop_details_link in enumerate(laptop_details_links):\n",
    "    if i==10:\n",
    "        break\n",
    "\n",
    "    browser.execute_script(\"arguments[0].click();\", laptop_details_link)\n",
    "    actions.pause(5).perform()\n",
    "    actions.reset_actions()\n",
    "\n",
    "    detail_child_window=browser.window_handles[-1]\n",
    "    browser.switch_to.window(detail_child_window)\n",
    "\n",
    "    title=WebDriverWait(browser,10).until(expected_conditions.presence_of_element_located((By.XPATH, title_xpath))).text.strip()\n",
    "    rating=WebDriverWait(browser,10).until(expected_conditions.presence_of_element_located((By.XPATH, rating_xpath))).text.strip()\n",
    "    price=WebDriverWait(browser,10).until(expected_conditions.element_to_be_clickable((By.XPATH, price_xpath))).text.strip()\n",
    "\n",
    "    titles.append(title)\n",
    "    ratings.append(rating)\n",
    "    prices.append(price)\n",
    "\n",
    "    browser.close()\n",
    "    browser.switch_to.window(parent_window)\n",
    "\n",
    "browser.quit()\n",
    "laptop_df.Title=titles\n",
    "laptop_df.Rating=ratings\n",
    "laptop_df.Price=prices\n",
    "laptop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f2dfa62a8b734",
   "metadata": {},
   "source": [
    "### Q6: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpage https://www.azquotes.com/\n",
    "2. Click on Top Quote\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e613aedab70199ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:09:50.402389Z",
     "start_time": "2024-04-11T15:06:51.144922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All quotes scraped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence,Deep Thought,Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration,Past,Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country,Peace,War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational,Motivational,Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July,Food,Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love,Inspirational,Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun,Two,Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational,Greatness,Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual,Truth,Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational,Leadership,Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Quote              Author  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                                       Type  \n",
       "0    Essence,Deep Thought,Transcendentalism  \n",
       "1                   Inspiration,Past,Trying  \n",
       "2                         Country,Peace,War  \n",
       "3          Inspirational,Motivational,Death  \n",
       "4                4th Of July,Food,Patriotic  \n",
       "..                                      ...  \n",
       "995         Love,Inspirational,Motivational  \n",
       "996                    Gun,Two,Qualms About  \n",
       "997     Inspirational,Greatness,Best Effort  \n",
       "998                    Spiritual,Truth,Yoga  \n",
       "999      Inspirational,Leadership,Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.common import TimeoutException\n",
    "\n",
    "browser=webdriver.Chrome()\n",
    "browser.maximize_window()\n",
    "browser.get('https://www.azquotes.com/')\n",
    "\n",
    "WebDriverWait(browser,10).until(expected_conditions.element_to_be_clickable((By.XPATH, '//div[@class=\"mainmenu\"]/ul/li[5]/a'))).click()\n",
    "actions=ActionChains(browser)\n",
    "actions.pause(5).perform()\n",
    "actions.reset_actions()\n",
    "\n",
    "quotes=[]\n",
    "authors=[]\n",
    "types=[]\n",
    "quotes_df=pd.DataFrame(columns=['Quote', 'Author', 'Type'])\n",
    "page_counter=1\n",
    "while True:\n",
    "    quotes_we=WebDriverWait(browser,10).until(expected_conditions.presence_of_all_elements_located((By.XPATH, '//div[@class=\"wrap-block\"]/p/a[2]')))\n",
    "    authors_we=WebDriverWait(browser,10).until(expected_conditions.presence_of_all_elements_located((By.XPATH, '//div[@class=\"author\"]/a')))\n",
    "    types1_we=WebDriverWait(browser,10).until(expected_conditions.presence_of_all_elements_located((By.XPATH, '//div[@class=\"tags\"]/a[1]')))\n",
    "    types2_we=WebDriverWait(browser,10).until(expected_conditions.presence_of_all_elements_located((By.XPATH, '//div[@class=\"tags\"]/a[2]')))\n",
    "    types3_we=WebDriverWait(browser,10).until(expected_conditions.presence_of_all_elements_located((By.XPATH, '//div[@class=\"tags\"]/a[3]')))\n",
    "    \n",
    "    for quote, author, type1, type2, type3 in zip(quotes_we, authors_we, types1_we, types2_we, types3_we):\n",
    "        quotes.append(quote.text.strip())\n",
    "        authors.append(author.text.strip())\n",
    "        types.append(f'{type1.text.strip()},{type2.text.strip()},{type3.text.strip()}')\n",
    "    if page_counter==1:\n",
    "        WebDriverWait(browser,10).until(expected_conditions.element_to_be_clickable((By.XPATH, '//div[@class=\"leftcol-inner\"]/div[4]/li[12]/a'))).click()\n",
    "        actions.pause(5).perform()\n",
    "        actions.reset_actions()\n",
    "    else:\n",
    "        try:\n",
    "            WebDriverWait(browser,10).until(expected_conditions.element_to_be_clickable((By.XPATH, '//div[@class=\"leftcol-inner\"]/div[4]/li[13]/a'))).click()\n",
    "            actions.pause(5).perform()\n",
    "            actions.reset_actions()\n",
    "        except TimeoutException:\n",
    "            print('All quotes scraped')\n",
    "            break\n",
    "    page_counter+=1\n",
    "\n",
    "browser.quit()\n",
    "quotes_df.Quote=quotes\n",
    "quotes_df.Author=authors\n",
    "quotes_df.Type=types\n",
    "quotes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3962197ab37ab70f",
   "metadata": {},
   "source": [
    "### Q7: Write a python program to display list of respected former Prime Ministers of India \n",
    "(i.e. Name,Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/general-knowledge/list-of-all-prime-ministers-of-india-1473165149-1\n",
    "scrap the mentioned data and make the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97949a3402594455",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:10:04.568006Z",
     "start_time": "2024-04-11T15:09:50.403653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Born-Dead</th>\n",
       "      <th>Term</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889‚Äì1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964; 16 years, 286 days</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>27 May 1964 to 9 June 1964,; 13 days</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>(1904‚Äì1966)</td>\n",
       "      <td>9 June 1964 to 11 January 1966; 1 year, 216 days</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gulzari Lal Nanda  (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>11 January 1966 to 24 January 1966; 13 days</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917‚Äì1984)</td>\n",
       "      <td>24 January 1966 to 24 March 1977; 11 years, 59...</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>(1896‚Äì1995)</td>\n",
       "      <td>24 March 1977 to  28 July 1979 ; 2 year, 126 days</td>\n",
       "      <td>Oldest to become PM (81 years old) and first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>(1902‚Äì1987)</td>\n",
       "      <td>28 July 1979 to 14 January 1980; 170 days</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917‚Äì1984)</td>\n",
       "      <td>14 January 1980 to 31 October 1984; 4 years, 2...</td>\n",
       "      <td>The first lady who served as PM for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>(1944‚Äì1991)</td>\n",
       "      <td>31 October 1984 to 2 December 1989; 5 years, 3...</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>(1931‚Äì2008)</td>\n",
       "      <td>2 December 1989 to 10 November 1990; 343 days</td>\n",
       "      <td>First PM to step down after a vote of no confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>(1927‚Äì2007)</td>\n",
       "      <td>10 November 1990 to 21 June 1991; 223 days</td>\n",
       "      <td>He belongs to  Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>(1921‚Äì2004)</td>\n",
       "      <td>21 June 1991 to 16 May 1996; 4 years, 330 days</td>\n",
       "      <td>First PM from South India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924- 2018)</td>\n",
       "      <td>16 May 1996 to 1 June 1996; 16 days</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>(born 1933)</td>\n",
       "      <td>1 June 1996 to 21 April 1997; 324 days</td>\n",
       "      <td>He belongs to  Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>(1919‚Äì2012)</td>\n",
       "      <td>21 April 1997 to 19 March 1998 ; 332 days</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924-2018)</td>\n",
       "      <td>19 March 1998 to 22 May 2004 ; 6 years, 64 days</td>\n",
       "      <td>The first non-congress PM who completed a full...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>(born 1932)</td>\n",
       "      <td>22 May 2004 to 26 May 2014   ; 10 years, 4 days</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>26 May 2014 - 2019</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>30 May 2019- Incumbent</td>\n",
       "      <td>First non-congress PM with two consecutive ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name     Born-Dead  \\\n",
       "1             Jawahar Lal Nehru   (1889‚Äì1964)   \n",
       "2     Gulzarilal Nanda (Acting)   (1898-1998)   \n",
       "3           Lal Bahadur Shastri   (1904‚Äì1966)   \n",
       "4   Gulzari Lal Nanda  (Acting)   (1898-1998)   \n",
       "5                 Indira Gandhi   (1917‚Äì1984)   \n",
       "6                 Morarji Desai   (1896‚Äì1995)   \n",
       "7                  Charan Singh   (1902‚Äì1987)   \n",
       "8                 Indira Gandhi   (1917‚Äì1984)   \n",
       "9                  Rajiv Gandhi   (1944‚Äì1991)   \n",
       "10                  V. P. Singh   (1931‚Äì2008)   \n",
       "11              Chandra Shekhar   (1927‚Äì2007)   \n",
       "12          P. V. Narasimha Rao   (1921‚Äì2004)   \n",
       "13         Atal Bihari Vajpayee  (1924- 2018)   \n",
       "14             H. D. Deve Gowda   (born 1933)   \n",
       "15           Inder Kumar Gujral   (1919‚Äì2012)   \n",
       "16         Atal Bihari Vajpayee   (1924-2018)   \n",
       "17               Manmohan Singh   (born 1932)   \n",
       "18                Narendra Modi   (born 1950)   \n",
       "19                Narendra Modi   (born 1950)   \n",
       "\n",
       "                                                 Term  \\\n",
       "1   15 August 1947 to 27 May 1964; 16 years, 286 days   \n",
       "2                27 May 1964 to 9 June 1964,; 13 days   \n",
       "3    9 June 1964 to 11 January 1966; 1 year, 216 days   \n",
       "4         11 January 1966 to 24 January 1966; 13 days   \n",
       "5   24 January 1966 to 24 March 1977; 11 years, 59...   \n",
       "6   24 March 1977 to  28 July 1979 ; 2 year, 126 days   \n",
       "7           28 July 1979 to 14 January 1980; 170 days   \n",
       "8   14 January 1980 to 31 October 1984; 4 years, 2...   \n",
       "9   31 October 1984 to 2 December 1989; 5 years, 3...   \n",
       "10      2 December 1989 to 10 November 1990; 343 days   \n",
       "11         10 November 1990 to 21 June 1991; 223 days   \n",
       "12     21 June 1991 to 16 May 1996; 4 years, 330 days   \n",
       "13                16 May 1996 to 1 June 1996; 16 days   \n",
       "14             1 June 1996 to 21 April 1997; 324 days   \n",
       "15          21 April 1997 to 19 March 1998 ; 332 days   \n",
       "16    19 March 1998 to 22 May 2004 ; 6 years, 64 days   \n",
       "17    22 May 2004 to 26 May 2014   ; 10 years, 4 days   \n",
       "18                                 26 May 2014 - 2019   \n",
       "19                             30 May 2019- Incumbent   \n",
       "\n",
       "                                              Remarks  \n",
       "1   The first prime minister of India and the long...  \n",
       "2                            First acting PM of India  \n",
       "3   He has given the slogan of 'Jai Jawan Jai Kisa...  \n",
       "4                                                   -  \n",
       "5                First female Prime Minister of India  \n",
       "6   Oldest to become PM (81 years old) and first t...  \n",
       "7             Only PM who did not face the Parliament  \n",
       "8   The first lady who served as PM for the second...  \n",
       "9                Youngest to become PM (40 years old)  \n",
       "10  First PM to step down after a vote of no confi...  \n",
       "11              He belongs to  Samajwadi Janata Party  \n",
       "12                          First PM from South India  \n",
       "13                             PM for shortest tenure  \n",
       "14                          He belongs to  Janata Dal  \n",
       "15                                             ------  \n",
       "16  The first non-congress PM who completed a full...  \n",
       "17                                      First Sikh PM  \n",
       "18  4th Prime Minister of India who served two con...  \n",
       "19  First non-congress PM with two consecutive ten...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "\n",
    "browser=webdriver.Chrome()\n",
    "browser.maximize_window()\n",
    "browser.get('https://www.jagranjosh.com/general-knowledge/list-of-all-prime-ministers-of-india-1473165149-1')\n",
    "\n",
    "all_table=WebDriverWait(browser,10).until(expected_conditions.presence_of_all_elements_located((By.XPATH, '//tbody//tr')))\n",
    "pm_df=pd.DataFrame(columns=['Name', 'Born-Dead', 'Term', 'Remarks'])\n",
    "for row_index, row in enumerate(all_table[1:-1]):\n",
    "    columns=row.find_elements(By.TAG_NAME, 'td')\n",
    "    name=columns[1].text.strip()\n",
    "    born_dead=columns[2].text.strip()\n",
    "    term=columns[3].text.strip()\n",
    "    term=re.compile(pattern='\\n').sub(repl='; ', string=term)\n",
    "    remark=columns[4].text.strip()\n",
    "    pm_df.loc[row_index+1]=[name,born_dead,term,remark]\n",
    "browser.quit()\n",
    "pm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a180031a634b54f",
   "metadata": {},
   "source": [
    "### Q8: Write a python program to display list of 50 Most expensive cars in the world\n",
    "(i.e. Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.motor1.com/\n",
    "2. Then You have to type in the search bar ‚Äô50 most expensive cars‚Äô\n",
    "3. Then click on 50 most expensive cars in the world..\n",
    "4. Then scrap the mentioned data and make the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bb15fea508cfca6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T15:10:38.490338Z",
     "start_time": "2024-04-11T15:10:04.569377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aston Martin Valour</td>\n",
       "      <td>$1.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mclaren Elva</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>McLaren Elva</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Zenvo TSR</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "      <td>$1.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "      <td>$1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "      <td>$1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "      <td>$2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "      <td>$2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "      <td>$2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lotus Evija</td>\n",
       "      <td>$2.1 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "      <td>$2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Delage D12</td>\n",
       "      <td>$2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ferrari Daytona SP3</td>\n",
       "      <td>$2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "      <td>$2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "      <td>$2.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "      <td>$2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "      <td>$2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "      <td>$2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "      <td>$2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mercedes</td>\n",
       "      <td>$2.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Zenvo Aurora</td>\n",
       "      <td>$2.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "      <td>$3.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "      <td>$3.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>McLaren Solus</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "      <td>$3.6 million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "      <td>$3.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "      <td>$3.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "      <td>$4.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "      <td>$4.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Pininfarina B95 Speedster</td>\n",
       "      <td>$4.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "      <td>$5.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Pagani Huayra Imola ‚Äì $5.4 Million</td>\n",
       "      <td>Pagani Huayra Imola ‚Äì $5.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "      <td>$5.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "      <td>$6.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "      <td>$7.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>777 Hypercar</td>\n",
       "      <td>$7.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Mercedes</td>\n",
       "      <td>$8.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "      <td>$9.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Rolls</td>\n",
       "      <td>$12.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "      <td>$13.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Rolls</td>\n",
       "      <td>$28.0 Million*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls</td>\n",
       "      <td>$30.0 Million*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Name                               Price\n",
       "0                  Aston Martin Valour                        $1.5 Million\n",
       "1                         Mclaren Elva                        $1.7 Million\n",
       "2                          Czinger 21C                        $1.7 Million\n",
       "3                        Ferrari Monza                        $1.7 Million\n",
       "4                   Gordon Murray T.33                        $1.7 Million\n",
       "5                    Koenigsegg Gemera                        $1.7 Million\n",
       "6                         McLaren Elva                        $1.7 Million\n",
       "7                            Zenvo TSR                        $1.7 Million\n",
       "8                   Hennessey Venom F5                        $1.8 Million\n",
       "9                      Bentley Bacalar                        $1.9 Million\n",
       "10       Hispano Suiza Carmen Boulogne                        $1.9 Million\n",
       "11              Bentley Mulliner Batur                        $2.0 Million\n",
       "12                        Deus Vayanne                        $2.0 Million\n",
       "13                         SSC Tuatara                        $2.0 Million\n",
       "14                         Lotus Evija                        $2.1 Million\n",
       "15                 Aston Martin Vulcan                        $2.3 Million\n",
       "16                          Delage D12                        $2.3 Million\n",
       "17                 Ferrari Daytona SP3                        $2.3 Million\n",
       "18                   McLaren Speedtail                        $2.3 Million\n",
       "19                        Rimac Nevera                        $2.4 Million\n",
       "20                       Pagani Utopia                        $2.5 Million\n",
       "21                Pininfarina Battista                        $2.5 Million\n",
       "22                  Gordon Murray T.50                        $2.6 Million\n",
       "23                Lamborghini Countach                        $2.6 Million\n",
       "24                            Mercedes                        $2.7 Million\n",
       "25                        Zenvo Aurora                        $2.8 Million\n",
       "26                 Aston Martin Victor                        $3.0 Million\n",
       "27         Hennessey Venom F5 Roadster                        $3.0 Million\n",
       "28                    Koenigsegg Jesko                        $3.0 Million\n",
       "29               Aston Martin Valkyrie                        $3.2 Million\n",
       "30           W Motors Lykan Hypersport                        $3.4 Million\n",
       "31                       McLaren Solus                        $3.5 Million\n",
       "32                    Lamborghini Sian                        $3.6 million\n",
       "33                    Koenigsegg CC850                        $3.7 Million\n",
       "34     Bugatti Chiron Super Sport 300+                        $3.9 Million\n",
       "35                  Lamborghini Veneno                        $4.5 Million\n",
       "36                      Bugatti Bolide                        $4.7 Million\n",
       "37           Pininfarina B95 Speedster                        $4.8 Million\n",
       "38                     Bugatti Mistral                        $5.0 Million\n",
       "39  Pagani Huayra Imola ‚Äì $5.4 Million  Pagani Huayra Imola ‚Äì $5.4 Million\n",
       "40                        Bugatti Divo                        $5.8 Million\n",
       "41                 SP Automotive Chaos                        $6.4 Million\n",
       "42                    Pagani Codalunga                        $7.4 Million\n",
       "43                        777 Hypercar                        $7.5 Million\n",
       "44                            Mercedes                        $8.0 Million\n",
       "45                  Bugatti Centodieci                        $9.0 Million\n",
       "46                               Rolls                       $12.8 Million\n",
       "47            Bugatti La Voiture Noire                       $13.4 Million\n",
       "48                               Rolls                      $28.0 Million*\n",
       "49                               Rolls                      $30.0 Million*"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "\n",
    "browser=webdriver.Chrome()\n",
    "browser.maximize_window()\n",
    "browser.get('https://www.motor1.com/')\n",
    "\n",
    "WebDriverWait(browser,10).until(expected_conditions.presence_of_element_located((By.XPATH, \"//input[@id='search_input']\"))).send_keys('50 most expensive cars')\n",
    "WebDriverWait(browser,10).until(expected_conditions.presence_of_element_located((By.XPATH, \"//button[@class='m1-search-panel-button m1-search-form-button-animate icon-search-svg']//*[name()='svg']\"))).click()\n",
    "WebDriverWait(browser,10).until(expected_conditions.element_to_be_clickable((By.XPATH, \"//a[normalize-space()='50 Most Expensive Cars In The World']\"))).click()\n",
    "\n",
    "car_detail_elements=WebDriverWait(browser,10).until(expected_conditions.presence_of_all_elements_located((By.XPATH, '//div[@class=\"postBody description e-content\"]/ul/li')))\n",
    "\n",
    "names=[]\n",
    "prices=[]\n",
    "car_df=pd.DataFrame(columns=['Name', 'Price'])\n",
    "p=re.compile(pattern='[-:]')\n",
    "for car_detail_element in car_detail_elements:\n",
    "    car_detail=car_detail_element.text.strip()\n",
    "    names.append(p.split(string=car_detail)[0].strip())\n",
    "    prices.append(p.split(string=car_detail)[-1].strip())\n",
    "browser.quit()\n",
    "car_df.Name=names\n",
    "car_df.Price=prices\n",
    "car_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
